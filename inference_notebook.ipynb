{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Copy_of_Inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9AjZsDnEmCo",
        "outputId": "31c28f9d-ddab-45a5-fede-714417d5fb5a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "g9AjZsDnEmCo",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVrKj1RaHodh"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install pytorch_transformers\n",
        "!pip install transformers\n",
        "\n",
        "clear_output()"
      ],
      "id": "RVrKj1RaHodh",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-08T05:00:37.379865Z",
          "start_time": "2021-11-08T05:00:37.373668Z"
        },
        "id": "municipal-parcel"
      },
      "source": [
        "# import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from pytorch_transformers import XLNetTokenizer\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import XLNetModel, XLNetForSequenceClassification\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "id": "municipal-parcel",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-08T05:00:49.945209Z",
          "start_time": "2021-11-08T05:00:49.938733Z"
        },
        "id": "higher-consensus"
      },
      "source": [
        "# Load the trained model and test data\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/techsoc-analytics-21-22/data/test.csv\")\n",
        "\n",
        "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenizer_xlnet = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "tokenizer_roberta = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "model_bert = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 500,    \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "model_bert.to(device)\n",
        "model_bert.load_state_dict(torch.load('/content/drive/MyDrive/techsoc-analytics-21-22/weights/bert/weights_bert_epochs7.pth'))\n",
        "\n",
        "model_roberta = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\", \n",
        "    num_labels = 500,    \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "model_roberta.to(device)\n",
        "model_roberta.load_state_dict(torch.load('/content/drive/MyDrive/techsoc-analytics-21-22/weights/roberta/weights_roberta_epochs8.pth'))\n",
        "\n",
        "\n",
        "model_xlnet = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=500)\n",
        "model_xlnet.to(device)\n",
        "model_xlnet.load_state_dict(torch.load('/content/drive/MyDrive/techsoc-analytics-21-22/weights/xlnet/weights_xlnet_8.pth'))\n",
        "\n",
        "clear_output()"
      ],
      "id": "higher-consensus",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDMQARsDot6u"
      },
      "source": [
        "def predict (model, dataloader):\n",
        "  \n",
        "  model.eval()\n",
        "  predictions  = []\n",
        "\n",
        "  for batch in dataloader:\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        result = model(b_input_ids, \n",
        "                      token_type_ids=None, \n",
        "                      attention_mask=b_input_mask,\n",
        "                      return_dict=True)\n",
        "    logits = result.logits\n",
        "\n",
        "  \n",
        "    # Move logits and labels to CPU\n",
        "    predictions.append(F.softmax(logits, dim = 1))\n",
        "\n",
        "  return torch.cat(predictions)\n"
      ],
      "id": "XDMQARsDot6u",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-08T05:02:59.207247Z",
          "start_time": "2021-11-08T05:02:59.197840Z"
        },
        "id": "bottom-gibson",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e25108da-06f4-4634-bd4b-f8643f8f2f25"
      },
      "source": [
        "%%time\n",
        "\n",
        "print(\"Code for Inference\")\n",
        "\n",
        "###########################################   PREPROCESSING   ################################################################################\n",
        "df['info'] = df['title'] + df['content']\n",
        "\n",
        "sentences_bert = df['info'].values\n",
        "#sentences_xlnet = [sentence + \" [SEP] [CLS]\" for sentence in sentences_bert]\n",
        "labels = [0]*len(df)\n",
        "\n",
        "####################################   INPUT ID'S AND ATTENTION MASKS   #######################################################################\n",
        "\n",
        "#tokenized_texts_xlnet = [tokenizer_xlnet.tokenize(sent) for sent in sentences_xlnet]\n",
        "\n",
        "MAX_LEN = 256\n",
        "'''\n",
        "input_ids_xlnet = [tokenizer_xlnet.convert_tokens_to_ids(x) for x in tokenized_texts_xlnet]\n",
        "input_ids_xlnet = pad_sequences(input_ids_xlnet, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "attention_masks_xlnet = []\n",
        "\n",
        "for seq in input_ids_xlnet:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks_xlnet.append(seq_mask) \n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids_xlnet)\n",
        "prediction_masks = torch.tensor(attention_masks_xlnet)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "'''\n",
        "input_ids_bert = []\n",
        "attention_masks_bert = []\n",
        "input_ids_roberta = []\n",
        "attention_masks_roberta = []\n",
        "\n",
        "\n",
        "for sent in sentences_bert:\n",
        "    \n",
        "    encoded_dict_bert = tokenizer_bert.encode_plus(sent, add_special_tokens = True,max_length = 256, padding = 'max_length', truncation = True, \n",
        "                                                    return_attention_mask = True, return_tensors = 'pt',     )\n",
        "    input_ids_bert.append(encoded_dict_bert['input_ids'])\n",
        "    attention_masks_bert.append(encoded_dict_bert['attention_mask'])\n",
        "    \n",
        "    encoded_dict_roberta = tokenizer_roberta.encode_plus(sent, add_special_tokens = True,max_length = 256, padding = 'max_length', \n",
        "                                                         truncation = True, return_attention_mask = True, return_tensors = 'pt',     )\n",
        "    input_ids_roberta.append(encoded_dict_roberta['input_ids'])\n",
        "    attention_masks_roberta.append(encoded_dict_roberta['attention_mask'])\n",
        "\n",
        "    \n",
        "input_ids_bert = torch.cat(input_ids_bert, dim=0)\n",
        "attention_masks_bert = torch.cat(attention_masks_bert, dim=0)\n",
        "\n",
        "input_ids_roberta = torch.cat(input_ids_roberta, dim=0)\n",
        "attention_masks_roberta = torch.cat(attention_masks_roberta, dim=0)\n",
        "\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "##################################################   CREATING THE DATALOADER   #######################################################################\n",
        "batch_size = 16\n",
        "'''\n",
        "prediction_data_xlnet = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler_xlnet = SequentialSampler(prediction_data_xlnet)\n",
        "prediction_dataloader_xlnet = DataLoader(prediction_data_xlnet, sampler=prediction_sampler_xlnet, batch_size=batch_size)\n",
        "'''\n",
        "prediction_data_bert = TensorDataset(input_ids_bert, attention_masks_bert, labels)\n",
        "prediction_sampler_bert = SequentialSampler(prediction_data_bert)\n",
        "prediction_dataloader_bert = DataLoader(prediction_data_bert, sampler=prediction_sampler_bert, batch_size=batch_size)\n",
        "\n",
        "prediction_data_roberta = TensorDataset(input_ids_roberta, attention_masks_roberta, labels)\n",
        "prediction_sampler_roberta = SequentialSampler(prediction_data_roberta)\n",
        "prediction_dataloader_roberta = DataLoader(prediction_data_roberta, sampler=prediction_sampler_roberta, batch_size=batch_size)\n",
        "\n",
        "##################################################### PREDICTING ################################################################\n",
        "\n",
        "probs_bert = predict(model_bert, prediction_dataloader_bert)\n",
        "#probs_xlnet = predict(model_xlnet, prediction_dataloader_xlnet)\n",
        "probs_roberta = predict(model_roberta, prediction_dataloader_roberta)\n",
        "\n",
        "probs_final= probs_bert + probs_roberta\n",
        "preds_final = torch.argmax(probs_final, dim = 1)\n",
        "\n",
        "# Full Code for running your inference (including any preprocessing you need to do on the test set)\n",
        "# In this Cell as a comment also mention the CPU and GPU of the system you are using to run this inference\n",
        "# CPU: \n",
        "# GPU: "
      ],
      "id": "bottom-gibson",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code for Inference\n",
            "CPU times: user 9min 23s, sys: 943 ms, total: 9min 24s\n",
            "Wall time: 9min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-08T05:03:23.210476Z",
          "start_time": "2021-11-08T05:03:23.205309Z"
        },
        "id": "fossil-crash"
      },
      "source": [
        "# Save Submission File\n",
        "preds_final = np.array(preds_final.cpu())\n",
        "submission = pd.DataFrame({'uid': [t for t in df['uid']], 'target_ind': preds_final})\n",
        "submission.to_csv('final_submission.csv')"
      ],
      "id": "fossil-crash",
      "execution_count": null,
      "outputs": []
    }
  ]
}