{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf56450d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:02:39.264767Z",
     "iopub.status.busy": "2021-10-31T07:02:39.263948Z",
     "iopub.status.idle": "2021-10-31T07:02:49.744786Z",
     "shell.execute_reply": "2021-10-31T07:02:49.745243Z",
     "shell.execute_reply.started": "2021-10-31T06:51:59.158854Z"
    },
    "papermill": {
     "duration": 10.519693,
     "end_time": "2021-10-31T07:02:49.745530",
     "exception": false,
     "start_time": "2021-10-31T07:02:39.225837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08224b46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:02:49.813174Z",
     "iopub.status.busy": "2021-10-31T07:02:49.811554Z",
     "iopub.status.idle": "2021-10-31T07:02:49.813765Z",
     "shell.execute_reply": "2021-10-31T07:02:49.814192Z",
     "shell.execute_reply.started": "2021-10-31T06:52:09.832653Z"
    },
    "papermill": {
     "duration": 0.041456,
     "end_time": "2021-10-31T07:02:49.814329",
     "exception": false,
     "start_time": "2021-10-31T07:02:49.772873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    PAD_token = 0   # Used for padding short sentences\n",
    "    SOS_token = 1   # Start-of-sentence token\n",
    "    EOS_token = 2   # End-of-sentence token\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {'PAD': 0, 'SOS': 1, 'EOS': 2, 'UNK':3}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\", 3: \"UNK\"}\n",
    "        self.num_words = 4\n",
    "        self.num_sentences = 0 \n",
    "        self.longest_sentence = 0\n",
    "    \n",
    "\n",
    "\n",
    "    def add_word(self, word):\n",
    "        \n",
    "        if word not in self.word2count:\n",
    "            # First entry of word into vocabulary\n",
    "            self.word2count[word] = 1\n",
    "        else:\n",
    "            if self.word2count[word]== 5:\n",
    "                self.word2index[word] = self.num_words\n",
    "                self.index2word[self.num_words] = word\n",
    "                self.num_words += 1\n",
    "                self.word2count[word] +=1\n",
    "            else:\n",
    "                self.word2count[word] += 1\n",
    "        \n",
    "        \n",
    "    def tokenizer(self,text):\n",
    "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
    "    \n",
    "    def add_sentence(self, sentence):\n",
    "        sentence_len = 0\n",
    "        #for word in sentence.split(' '):\n",
    "        for word in self.tokenizer(sentence):\n",
    "            sentence_len += 1\n",
    "            self.add_word(word)\n",
    "        if sentence_len > self.longest_sentence:\n",
    "            # This is the longest sentence\n",
    "            self.longest_sentence = sentence_len\n",
    "        # Count the number of sentences\n",
    "        self.num_sentences += 1\n",
    "\n",
    "    def to_word(self, index):\n",
    "        return self.index2word[index]\n",
    "\n",
    "    def to_index(self, word):\n",
    "        return self.word2index[word]\n",
    "\n",
    "vocab = Vocabulary('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e3dcc3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:02:49.872604Z",
     "iopub.status.busy": "2021-10-31T07:02:49.872006Z",
     "iopub.status.idle": "2021-10-31T07:02:50.904061Z",
     "shell.execute_reply": "2021-10-31T07:02:50.903441Z",
     "shell.execute_reply.started": "2021-10-31T06:52:09.846413Z"
    },
    "papermill": {
     "duration": 1.062395,
     "end_time": "2021-10-31T07:02:50.904239",
     "exception": false,
     "start_time": "2021-10-31T07:02:49.841844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>uid</th>\n",
       "      <th>target_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Premium quality five pocket jean from Wrangler...</td>\n",
       "      <td>Amazon.com: Wrangler Men's Rugged Wear Relaxed...</td>\n",
       "      <td>B0000CBALT</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you're looking for a different kind of anim...</td>\n",
       "      <td>Sakura Diaries - Complete Series Collector's E...</td>\n",
       "      <td>B00005QFDT</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First things first: Yes, Thinking XXX features...</td>\n",
       "      <td>Thinking XXX (Extended Cut) (2006)</td>\n",
       "      <td>B000BNXD50</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feathertouch. 100% Polyester Machine Wash Warm...</td>\n",
       "      <td>Amazon.com: Petite Feathertouch Pull-On Pant: ...</td>\n",
       "      <td>B0002LK9V2</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When you need outstanding fuel delivery, easy ...</td>\n",
       "      <td>ACDelco EP386 Fuel Pump</td>\n",
       "      <td>B000C9PA54</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Premium quality five pocket jean from Wrangler...   \n",
       "1  If you're looking for a different kind of anim...   \n",
       "2  First things first: Yes, Thinking XXX features...   \n",
       "3  Feathertouch. 100% Polyester Machine Wash Warm...   \n",
       "4  When you need outstanding fuel delivery, easy ...   \n",
       "\n",
       "                                               title         uid  target_ind  \n",
       "0  Amazon.com: Wrangler Men's Rugged Wear Relaxed...  B0000CBALT         247  \n",
       "1  Sakura Diaries - Complete Series Collector's E...  B00005QFDT         453  \n",
       "2                 Thinking XXX (Extended Cut) (2006)  B000BNXD50         228  \n",
       "3  Amazon.com: Petite Feathertouch Pull-On Pant: ...  B0002LK9V2         223  \n",
       "4                            ACDelco EP386 Fuel Pump  B000C9PA54         312  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/dataset/train.csv')\n",
    "test_df = pd.read_csv('../input/dataset/test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b7b116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:02:50.967794Z",
     "iopub.status.busy": "2021-10-31T07:02:50.967121Z",
     "iopub.status.idle": "2021-10-31T07:02:50.969711Z",
     "shell.execute_reply": "2021-10-31T07:02:50.970206Z",
     "shell.execute_reply.started": "2021-10-31T06:52:10.870151Z"
    },
    "papermill": {
     "duration": 0.038383,
     "end_time": "2021-10-31T07:02:50.970331",
     "exception": false,
     "start_time": "2021-10-31T07:02:50.931948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Socket Cap Screws are reliable and durable and...</td>\n",
       "      <td>Alloy Steel Socket Cap Screw, Flat Head, Hex S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This O-ring is made of black Buna-nitrile, is ...</td>\n",
       "      <td>-161 Buna O-Ring, 70A Durometer, Black, 5-1/2&amp;...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This Viton O-ring is black in color, round in ...</td>\n",
       "      <td>-445 Viton O-Ring, 75A Durometer, Black, 8&amp;#03...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This 5-ounce lightweight pique knit sport shir...</td>\n",
       "      <td>Amazon.com: Port Authority Silk Touch Sport Sh...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This O-ring is made of black Buna-nitrile, is ...</td>\n",
       "      <td>-359 Buna O-Ring, 70A Durometer, Black, 5-3/4&amp;...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Socket Cap Screws are reliable and durable and...   \n",
       "1  This O-ring is made of black Buna-nitrile, is ...   \n",
       "2  This Viton O-ring is black in color, round in ...   \n",
       "3  This 5-ounce lightweight pique knit sport shir...   \n",
       "4  This O-ring is made of black Buna-nitrile, is ...   \n",
       "\n",
       "                                               title  uid  \n",
       "0  Alloy Steel Socket Cap Screw, Flat Head, Hex S...    0  \n",
       "1  -161 Buna O-Ring, 70A Durometer, Black, 5-1/2&...    1  \n",
       "2  -445 Viton O-Ring, 75A Durometer, Black, 8&#03...    2  \n",
       "3  Amazon.com: Port Authority Silk Touch Sport Sh...    3  \n",
       "4  -359 Buna O-Ring, 70A Durometer, Black, 5-3/4&...    4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e16ee1d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:02:51.041352Z",
     "iopub.status.busy": "2021-10-31T07:02:51.039637Z",
     "iopub.status.idle": "2021-10-31T07:02:51.045277Z",
     "shell.execute_reply": "2021-10-31T07:02:51.044850Z",
     "shell.execute_reply.started": "2021-10-31T06:52:10.881081Z"
    },
    "papermill": {
     "duration": 0.047583,
     "end_time": "2021-10-31T07:02:51.045386",
     "exception": false,
     "start_time": "2021-10-31T07:02:50.997803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min label: 0 \n",
      "max label: 499\n"
     ]
    }
   ],
   "source": [
    "m1 = min(df['target_ind'])\n",
    "m2 = max(df['target_ind'])\n",
    "print (f'min label: {m1} \\nmax label: {m2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad9f30d",
   "metadata": {
    "papermill": {
     "duration": 0.028511,
     "end_time": "2021-10-31T07:02:51.102471",
     "exception": false,
     "start_time": "2021-10-31T07:02:51.073960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are 500 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445311df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:02:51.230960Z",
     "iopub.status.busy": "2021-10-31T07:02:51.190264Z",
     "iopub.status.idle": "2021-10-31T07:02:51.234561Z",
     "shell.execute_reply": "2021-10-31T07:02:51.234037Z",
     "shell.execute_reply.started": "2021-10-31T06:52:10.904845Z"
    },
    "papermill": {
     "duration": 0.101434,
     "end_time": "2021-10-31T07:02:51.234713",
     "exception": false,
     "start_time": "2021-10-31T07:02:51.133279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['info'] = df['content'] + ' ' + df['title']\n",
    "test_df['info'] =  test_df['content'] + ' ' + test_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c6efd01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:02:51.332044Z",
     "iopub.status.busy": "2021-10-31T07:02:51.326857Z",
     "iopub.status.idle": "2021-10-31T07:03:28.263261Z",
     "shell.execute_reply": "2021-10-31T07:03:28.263748Z",
     "shell.execute_reply.started": "2021-10-31T06:52:10.974117Z"
    },
    "papermill": {
     "duration": 36.999255,
     "end_time": "2021-10-31T07:03:28.263916",
     "exception": false,
     "start_time": "2021-10-31T07:02:51.264661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_words</th>\n",
       "      <th>content_words</th>\n",
       "      <th>info_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35112.000000</td>\n",
       "      <td>35112.000000</td>\n",
       "      <td>35112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.958903</td>\n",
       "      <td>173.547163</td>\n",
       "      <td>173.547163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.089399</td>\n",
       "      <td>232.912858</td>\n",
       "      <td>232.912858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>10331.000000</td>\n",
       "      <td>10331.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        title_words  content_words    info_words\n",
       "count  35112.000000   35112.000000  35112.000000\n",
       "mean      12.958903     173.547163    173.547163\n",
       "std        9.089399     232.912858    232.912858\n",
       "min        1.000000       1.000000      1.000000\n",
       "25%        6.000000      48.000000     48.000000\n",
       "50%       10.000000     103.000000    103.000000\n",
       "75%       17.000000     240.000000    240.000000\n",
       "max       57.000000   10331.000000  10331.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_words'] = [len(vocab.tokenizer(t)) for t in df['title']]\n",
    "df['content_words'] = [len(vocab.tokenizer(t)) for t in df['content']]\n",
    "df['info_words'] = [len(vocab.tokenizer(t)) for t in df['content']]\n",
    "df[['title_words', 'content_words', 'info_words']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af053aff",
   "metadata": {
    "papermill": {
     "duration": 0.028703,
     "end_time": "2021-10-31T07:03:28.321084",
     "exception": false,
     "start_time": "2021-10-31T07:03:28.292381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll remove some outliers from the data ( products which have very high number of words in either title or content )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a6a2b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:03:28.383705Z",
     "iopub.status.busy": "2021-10-31T07:03:28.382640Z",
     "iopub.status.idle": "2021-10-31T07:03:28.395378Z",
     "shell.execute_reply": "2021-10-31T07:03:28.395884Z",
     "shell.execute_reply.started": "2021-10-31T06:52:47.982199Z"
    },
    "papermill": {
     "duration": 0.046673,
     "end_time": "2021-10-31T07:03:28.396027",
     "exception": false,
     "start_time": "2021-10-31T07:03:28.349354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9702950558213717"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = df['info_words'].describe()['mean']\n",
    "std = df['info_words'].describe()['std']\n",
    "u = mean + 2*std\n",
    "df1 = df[df['info_words'] <= u]\n",
    "len(df1)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18ede896",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:03:28.526499Z",
     "iopub.status.busy": "2021-10-31T07:03:28.525669Z",
     "iopub.status.idle": "2021-10-31T07:03:28.541409Z",
     "shell.execute_reply": "2021-10-31T07:03:28.541835Z",
     "shell.execute_reply.started": "2021-10-31T06:52:48.011104Z"
    },
    "papermill": {
     "duration": 0.05151,
     "end_time": "2021-10-31T07:03:28.541961",
     "exception": false,
     "start_time": "2021-10-31T07:03:28.490451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_words</th>\n",
       "      <th>content_words</th>\n",
       "      <th>info_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34069.000000</td>\n",
       "      <td>34069.000000</td>\n",
       "      <td>34069.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.052834</td>\n",
       "      <td>144.941707</td>\n",
       "      <td>144.941707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.115579</td>\n",
       "      <td>124.977805</td>\n",
       "      <td>124.977805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>637.000000</td>\n",
       "      <td>637.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        title_words  content_words    info_words\n",
       "count  34069.000000   34069.000000  34069.000000\n",
       "mean      13.052834     144.941707    144.941707\n",
       "std        9.115579     124.977805    124.977805\n",
       "min        1.000000       1.000000      1.000000\n",
       "25%        6.000000      46.000000     46.000000\n",
       "50%       10.000000      96.000000     96.000000\n",
       "75%       17.000000     235.000000    235.000000\n",
       "max       57.000000     637.000000    637.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['title_words', 'content_words', 'info_words']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54db0c5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:03:28.606273Z",
     "iopub.status.busy": "2021-10-31T07:03:28.605699Z",
     "iopub.status.idle": "2021-10-31T07:03:28.958044Z",
     "shell.execute_reply": "2021-10-31T07:03:28.957574Z",
     "shell.execute_reply.started": "2021-10-31T06:52:48.034478Z"
    },
    "papermill": {
     "duration": 0.385876,
     "end_time": "2021-10-31T07:03:28.958207",
     "exception": false,
     "start_time": "2021-10-31T07:03:28.572331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = df1.groupby('target_ind', group_keys=False).apply(lambda x: x.sample((int(0.8*len(x)))))\n",
    "val_df = df1[~df1.isin(train_df)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b77e346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:03:29.051929Z",
     "iopub.status.busy": "2021-10-31T07:03:29.041524Z",
     "iopub.status.idle": "2021-10-31T07:05:21.468066Z",
     "shell.execute_reply": "2021-10-31T07:05:21.468513Z",
     "shell.execute_reply.started": "2021-10-31T06:52:48.385956Z"
    },
    "papermill": {
     "duration": 112.480385,
     "end_time": "2021-10-31T07:05:21.468663",
     "exception": false,
     "start_time": "2021-10-31T07:03:28.988278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27054, 7534)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding words to the vocabulary \n",
    "vocab_test = Vocabulary('rand')\n",
    "for sentence in test_df['info']:\n",
    "    vocab_test.add_sentence(sentence)\n",
    "\n",
    "for sentence in train_df['info']:\n",
    "    vocab.add_sentence(sentence)\n",
    "\n",
    "sent_idxs = []\n",
    "captions = []\n",
    "for idx, sentence in enumerate (train_df['info']):\n",
    "    i = 0\n",
    "    for word in vocab.tokenizer(sentence):\n",
    "        if word not in vocab.word2index:\n",
    "            sent_idxs.append(3)\n",
    "        else:\n",
    "            sent_idxs.append(vocab.to_index(word))\n",
    "        i+=1\n",
    "    while i < ((vocab_test.longest_sentence)):\n",
    "        sent_idxs.append(0)\n",
    "        i+=1\n",
    "    captions.append(sent_idxs)\n",
    "    sent_idxs = []\n",
    "    \n",
    "# converting list of word tokens to numpy array\n",
    "train_info = np.array(captions)\n",
    "train_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d7f33ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:05:21.559422Z",
     "iopub.status.busy": "2021-10-31T07:05:21.554174Z",
     "iopub.status.idle": "2021-10-31T07:05:49.945960Z",
     "shell.execute_reply": "2021-10-31T07:05:49.947118Z",
     "shell.execute_reply.started": "2021-10-31T06:54:39.764570Z"
    },
    "papermill": {
     "duration": 28.449208,
     "end_time": "2021-10-31T07:05:49.947330",
     "exception": false,
     "start_time": "2021-10-31T07:05:21.498122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7015, 7534)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding words to the vocabulary \n",
    "for sentence in val_df['info']:\n",
    "    vocab.add_sentence(sentence)\n",
    "\n",
    "sent_idxs = []\n",
    "captions = []\n",
    "for idx, sentence in enumerate (val_df['info']):\n",
    "    i = 0\n",
    "    for word in vocab.tokenizer(sentence):\n",
    "        if word not in vocab.word2index:\n",
    "            sent_idxs.append(3)\n",
    "        else:\n",
    "            sent_idxs.append(vocab.to_index(word))\n",
    "        i+=1\n",
    "    while i < ((vocab_test.longest_sentence)):\n",
    "        sent_idxs.append(0)\n",
    "        i+=1\n",
    "    captions.append(sent_idxs)\n",
    "    sent_idxs = []\n",
    "    \n",
    "# converting list of word tokens to numpy array\n",
    "val_info = np.array(captions)\n",
    "val_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03d5ad27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:05:50.270136Z",
     "iopub.status.busy": "2021-10-31T07:05:50.259983Z",
     "iopub.status.idle": "2021-10-31T07:06:20.043507Z",
     "shell.execute_reply": "2021-10-31T07:06:20.042833Z",
     "shell.execute_reply.started": "2021-10-31T06:55:06.873188Z"
    },
    "papermill": {
     "duration": 29.977793,
     "end_time": "2021-10-31T07:06:20.043641",
     "exception": false,
     "start_time": "2021-10-31T07:05:50.065848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8106, 7534)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_idxs = []\n",
    "captions = []\n",
    "for idx, sentence in enumerate (test_df['info']):\n",
    "    i = 0\n",
    "    for word in vocab.tokenizer(sentence):\n",
    "        if word not in vocab.word2index:\n",
    "            sent_idxs.append(3)\n",
    "        else:\n",
    "            sent_idxs.append(vocab.to_index(word))\n",
    "        i+=1\n",
    "    while i < ((vocab_test.longest_sentence)):\n",
    "        sent_idxs.append(0)\n",
    "        i+=1\n",
    "    captions.append(sent_idxs)\n",
    "    sent_idxs = []\n",
    "    \n",
    "# converting list of word tokens to numpy array\n",
    "test_info = np.array(captions)\n",
    "test_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "361fc4e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:06:20.321569Z",
     "iopub.status.busy": "2021-10-31T07:06:20.320942Z",
     "iopub.status.idle": "2021-10-31T07:06:20.323551Z",
     "shell.execute_reply": "2021-10-31T07:06:20.323961Z",
     "shell.execute_reply.started": "2021-10-31T06:55:36.223323Z"
    },
    "papermill": {
     "duration": 0.038766,
     "end_time": "2021-10-31T07:06:20.324105",
     "exception": false,
     "start_time": "2021-10-31T07:06:20.285339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23753"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc907fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:06:20.392422Z",
     "iopub.status.busy": "2021-10-31T07:06:20.391850Z",
     "iopub.status.idle": "2021-10-31T07:07:05.913216Z",
     "shell.execute_reply": "2021-10-31T07:07:05.912727Z",
     "shell.execute_reply.started": "2021-10-31T06:55:36.236941Z"
    },
    "papermill": {
     "duration": 45.558131,
     "end_time": "2021-10-31T07:07:05.913357",
     "exception": false,
     "start_time": "2021-10-31T07:06:20.355226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocabs = vocab.word2index.keys()\n",
    "\n",
    "def load_embeds(root_dir):\n",
    "    embeddings_index = dict()\n",
    "    f = open(root_dir)\n",
    "\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "    f.close()\n",
    "    return embeddings_index\n",
    "embeddings_index = load_embeds('../input/glove6b300dtxt/glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c322546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:07:06.004930Z",
     "iopub.status.busy": "2021-10-31T07:07:05.979394Z",
     "iopub.status.idle": "2021-10-31T07:07:06.007605Z",
     "shell.execute_reply": "2021-10-31T07:07:06.008009Z",
     "shell.execute_reply.started": "2021-10-31T06:56:22.160157Z"
    },
    "papermill": {
     "duration": 0.062508,
     "end_time": "2021-10-31T07:07:06.008167",
     "exception": false,
     "start_time": "2021-10-31T07:07:05.945659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.6560e-02,  2.1318e-01, -7.4364e-03, -4.5854e-01, -3.5639e-02,\n",
       "        2.3643e-01, -2.8836e-01,  2.1521e-01, -1.3486e-01, -1.6413e+00,\n",
       "       -2.6091e-01,  3.2434e-02,  5.6621e-02, -4.3296e-02, -2.1672e-02,\n",
       "        2.2476e-01, -7.5129e-02, -6.7018e-02, -1.4247e-01,  3.8825e-02,\n",
       "       -1.8951e-01,  2.9977e-01,  3.9305e-01,  1.7887e-01, -1.7343e-01,\n",
       "       -2.1178e-01,  2.3617e-01, -6.3681e-02, -4.2318e-01, -1.1661e-01,\n",
       "        9.3754e-02,  1.7296e-01, -3.3073e-01,  4.9112e-01, -6.8995e-01,\n",
       "       -9.2462e-02,  2.4742e-01, -1.7991e-01,  9.7908e-02,  8.3118e-02,\n",
       "        1.5299e-01, -2.7276e-01, -3.8934e-02,  5.4453e-01,  5.3737e-01,\n",
       "        2.9105e-01, -7.3514e-03,  4.7880e-02, -4.0760e-01, -2.6759e-02,\n",
       "        1.7919e-01,  1.0977e-02, -1.0963e-01, -2.6395e-01,  7.3990e-02,\n",
       "        2.6236e-01, -1.5080e-01,  3.4623e-01,  2.5758e-01,  1.1971e-01,\n",
       "       -3.7135e-02, -7.1593e-02,  4.3898e-01, -4.0764e-02,  1.6425e-02,\n",
       "       -4.4640e-01,  1.7197e-01,  4.6246e-02,  5.8639e-02,  4.1499e-02,\n",
       "        5.3948e-01,  5.2495e-01,  1.1361e-01, -4.8315e-02, -3.6385e-01,\n",
       "        1.8704e-01,  9.2761e-02, -1.1129e-01, -4.2085e-01,  1.3992e-01,\n",
       "       -3.9338e-01, -6.7945e-02,  1.2188e-01,  1.6707e-01,  7.5169e-02,\n",
       "       -1.5529e-02, -1.9499e-01,  1.9638e-01,  5.3194e-02,  2.5170e-01,\n",
       "       -3.4845e-01, -1.0638e-01, -3.4692e-01, -1.9024e-01, -2.0040e-01,\n",
       "        1.2154e-01, -2.9208e-01,  2.3353e-02, -1.1618e-01, -3.5768e-01,\n",
       "        6.2304e-02,  3.5884e-01,  2.9060e-02,  7.3005e-03,  4.9482e-03,\n",
       "       -1.5048e-01, -1.2313e-01,  1.9337e-01,  1.2173e-01,  4.4503e-01,\n",
       "        2.5147e-01,  1.0781e-01, -1.7716e-01,  3.8691e-02,  8.1530e-02,\n",
       "        1.4667e-01,  6.3666e-02,  6.1332e-02, -7.5569e-02, -3.7724e-01,\n",
       "        1.5850e-02, -3.0342e-01,  2.8374e-01, -4.2013e-02, -4.0715e-02,\n",
       "       -1.5269e-01,  7.4980e-02,  1.5577e-01,  1.0433e-01,  3.1393e-01,\n",
       "        1.9309e-01,  1.9429e-01,  1.5185e-01, -1.0192e-01, -1.8785e-02,\n",
       "        2.0791e-01,  1.3366e-01,  1.9038e-01, -2.5558e-01,  3.0400e-01,\n",
       "       -1.8960e-02,  2.0147e-01, -4.2110e-01, -7.5156e-03, -2.7977e-01,\n",
       "       -1.9314e-01,  4.6204e-02,  1.9971e-01, -3.0207e-01,  2.5735e-01,\n",
       "        6.8107e-01, -1.9409e-01,  2.3984e-01,  2.2493e-01,  6.5224e-01,\n",
       "       -1.3561e-01, -1.7383e-01, -4.8209e-02, -1.1860e-01,  2.1588e-03,\n",
       "       -1.9525e-02,  1.1948e-01,  1.9346e-01, -4.0820e-01, -8.2966e-02,\n",
       "        1.6626e-01, -1.0601e-01,  3.5861e-01,  1.6922e-01,  7.2590e-02,\n",
       "       -2.4803e-01, -1.0024e-01, -5.2491e-01, -1.7745e-01, -3.6647e-01,\n",
       "        2.6180e-01, -1.2077e-02,  8.3190e-02, -2.1528e-01,  4.1045e-01,\n",
       "        2.9136e-01,  3.0869e-01,  7.8864e-02,  3.2207e-01, -4.1023e-02,\n",
       "       -1.0970e-01, -9.2041e-02, -1.2339e-01, -1.6416e-01,  3.5382e-01,\n",
       "       -8.2774e-02,  3.3171e-01, -2.4738e-01, -4.8928e-02,  1.5746e-01,\n",
       "        1.8988e-01, -2.6642e-02,  6.3315e-02, -1.0673e-02,  3.4089e-01,\n",
       "        1.4106e+00,  1.3417e-01,  2.8191e-01, -2.5940e-01,  5.5267e-02,\n",
       "       -5.2425e-02, -2.5789e-01,  1.9127e-02, -2.2084e-02,  3.2113e-01,\n",
       "        6.8818e-02,  5.1207e-01,  1.6478e-01, -2.0194e-01,  2.9232e-01,\n",
       "        9.8575e-02,  1.3145e-02, -1.0652e-01,  1.3510e-01, -4.5332e-02,\n",
       "        2.0697e-01, -4.8425e-01, -4.4706e-01,  3.3305e-03,  2.9264e-03,\n",
       "       -1.0975e-01, -2.3325e-01,  2.2442e-01, -1.0503e-01,  1.2339e-01,\n",
       "        1.0978e-01,  4.8994e-02, -2.5157e-01,  4.0319e-01,  3.5318e-01,\n",
       "        1.8651e-01, -2.3622e-02, -1.2734e-01,  1.1475e-01,  2.7359e-01,\n",
       "       -2.1866e-01,  1.5794e-02,  8.1754e-01, -2.3792e-02, -8.5469e-01,\n",
       "       -1.6203e-01,  1.8076e-01,  2.8014e-02, -1.4340e-01,  1.3139e-03,\n",
       "       -9.1735e-02, -8.9704e-02,  1.1105e-01, -1.6703e-01,  6.8377e-02,\n",
       "       -8.7388e-02, -3.9789e-02,  1.4184e-02,  2.1187e-01,  2.8579e-01,\n",
       "       -2.8797e-01, -5.8996e-02, -3.2436e-02, -4.7009e-03, -1.7052e-01,\n",
       "       -3.4741e-02, -1.1489e-01,  7.5093e-02,  9.9526e-02,  4.8183e-02,\n",
       "       -7.3775e-02, -4.1817e-01,  4.1268e-03,  4.4414e-01, -1.6062e-01,\n",
       "        1.4294e-01, -2.2628e+00, -2.7347e-02,  8.1311e-01,  7.7417e-01,\n",
       "       -2.5639e-01, -1.1576e-01, -1.1982e-01, -2.1363e-01,  2.8429e-02,\n",
       "        2.7261e-01,  3.1026e-02,  9.6782e-02,  6.7769e-03,  1.4082e-01,\n",
       "       -1.3064e-02, -2.9686e-01, -7.9913e-02,  1.9500e-01,  3.1549e-02,\n",
       "        2.8506e-01, -8.7461e-02,  9.0611e-03, -2.0989e-01,  5.3913e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d7e5ea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:07:06.078395Z",
     "iopub.status.busy": "2021-10-31T07:07:06.077576Z",
     "iopub.status.idle": "2021-10-31T07:07:06.243621Z",
     "shell.execute_reply": "2021-10-31T07:07:06.244029Z",
     "shell.execute_reply.started": "2021-10-31T06:56:22.171160Z"
    },
    "papermill": {
     "duration": 0.203911,
     "end_time": "2021-10-31T07:07:06.244205",
     "exception": false,
     "start_time": "2021-10-31T07:07:06.040294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23753, 300])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "def load_embed_weights(embeddings_index, embed_dim, vocab, vocab_size):\n",
    "    matrix_len = vocab_size\n",
    "    weights_matrix = np.zeros((matrix_len, embed_dim))\n",
    "    words_found = 0\n",
    "\n",
    "    for i, word in enumerate(vocab):\n",
    "        try: \n",
    "            weights_matrix[i] = embeddings_index[word]\n",
    "            words_found += 1\n",
    "        except KeyError:\n",
    "            weights_matrix[i] = np.random.normal(scale=0.6, size=(embed_dim, ))\n",
    "    weights_matrix = torch.tensor(weights_matrix)\n",
    "    return weights_matrix\n",
    "weights_matrix = load_embed_weights(embeddings_index, 300, vocabs, vocab.num_words)\n",
    "weights_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e90b03d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:07:06.316759Z",
     "iopub.status.busy": "2021-10-31T07:07:06.316092Z",
     "iopub.status.idle": "2021-10-31T07:07:06.701980Z",
     "shell.execute_reply": "2021-10-31T07:07:06.702525Z",
     "shell.execute_reply.started": "2021-10-31T06:56:22.350408Z"
    },
    "papermill": {
     "duration": 0.426026,
     "end_time": "2021-10-31T07:07:06.702692",
     "exception": false,
     "start_time": "2021-10-31T07:07:06.276666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, train_data,info, test = False):\n",
    "        self.info = info\n",
    "        self.train_data = train_data\n",
    "        self.t = test\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.t:\n",
    "            return self.info[index]\n",
    "        else:\n",
    "            return self.info[index], self.train_data['target_ind'].iloc[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "\n",
    "\n",
    "trainset = Dataset(train_df, train_info)\n",
    "val_df['target_ind'] = [int(v) for v in (val_df['target_ind'])]\n",
    "valset = Dataset(val_df, val_info)\n",
    "testset = Dataset(test_df, test_info, test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d22dc06f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:07:06.943888Z",
     "iopub.status.busy": "2021-10-31T07:07:06.942963Z",
     "iopub.status.idle": "2021-10-31T07:07:06.946899Z",
     "shell.execute_reply": "2021-10-31T07:07:06.947525Z",
     "shell.execute_reply.started": "2021-10-31T06:56:22.759124Z"
    },
    "papermill": {
     "duration": 0.067316,
     "end_time": "2021-10-31T07:07:06.947708",
     "exception": false,
     "start_time": "2021-10-31T07:07:06.880392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle = True)\n",
    "valloader = DataLoader(dataset=valset, batch_size=batch_size, shuffle = True)\n",
    "testloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a00b233b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:07:07.057773Z",
     "iopub.status.busy": "2021-10-31T07:07:07.057163Z",
     "iopub.status.idle": "2021-10-31T07:07:07.915863Z",
     "shell.execute_reply": "2021-10-31T07:07:07.915170Z",
     "shell.execute_reply.started": "2021-10-31T06:56:22.771711Z"
    },
    "papermill": {
     "duration": 0.911389,
     "end_time": "2021-10-31T07:07:07.916042",
     "exception": false,
     "start_time": "2021-10-31T07:07:07.004653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socket cap screws are reliable and durable and are used in many applications .   they are available in a variety of head styles and materials . alloy steel is steel that has been alloyed with other materials to improve overall physical properties .   steels are designated by a 4 number sae steel grade .   the first two digits indicate the primary materials used to form the steel .   the last 2 digits identify the percentage of carbon for the alloy ( in hundredths ) .   tensile strength ranges for the alloys typically used in these fasteners range from 170,000 to 180,000 psi ( pounds per square inch ) , making these amongst the strongest of materials .   flat head fasteners are designed to fit flush to the surface when used with countersunk holes .   length is measured from the top of the head .   hex socket drive systems are driven by hex wrenches or power tools with hexagonal bits .   a threaded fastener 's size name includes information about the major external diameter , followed by the threads per inch , which indicates if it is coarse or fine .   coarse threads are better when working with brittle materials ; they are sturdier and are easier to thread and unthread compared to fine .   coarse threading also allows for thicker coatings and platings . alloy steel socket cap screw , flat head , hex socket drive , 1/4&#034;-20 , 2&#034 ; length ( pack of 25 ) PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in testloader:\n",
    "    for i in c[0]:\n",
    "        print(vocab.to_word(int(i)), end = ' ')\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2260600c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:07:08.055760Z",
     "iopub.status.busy": "2021-10-31T07:07:08.054952Z",
     "iopub.status.idle": "2021-10-31T07:07:08.060056Z",
     "shell.execute_reply": "2021-10-31T07:07:08.060665Z",
     "shell.execute_reply.started": "2021-10-31T06:56:24.106576Z"
    },
    "papermill": {
     "duration": 0.069877,
     "end_time": "2021-10-31T07:07:08.060846",
     "exception": false,
     "start_time": "2021-10-31T07:07:07.990969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class Model(nn.Module):\\n    \\n    def __init__(self, embed_size, hidden_size,  vocab_size, num_labels ):\\n        super().__init__()\\n        \\n        self.embed_size = embed_size\\n        self.vocab_size = vocab_size\\n        self.hidden_size = hidden_size\\n        self.num_labels = num_labels\\n        \\n        self.embed = nn.Embedding(num_embeddings = self.vocab_size, embedding_dim = self.embed_size)\\n        self.embed.weight.requires_grad = False\\n        self.embed.load_state_dict({'weight': weights_matrix})\\n\\n        \\n      \\n        self.title_lstm = nn.LSTM(input_size = self.embed_size, hidden_size = self.hidden_size, bidirectional = True, batch_first = True, num_layers = 2)\\n        self.content_lstm = nn.LSTM(input_size = self.embed_size, hidden_size = self.hidden_size, bidirectional = True, batch_first = True, num_layers = 2)\\n        \\n        self.attention = nn.Linear(2*self.hidden_size, 2*self.hidden_size, bias = False)\\n        \\n        self.fc = nn.Linear(7532, self.num_labels)\\n        self.fc1 = nn.Linear(4*hidden_size, self.num_labels)\\n        self.relu = nn.ReLU()\\n        self.dropout = nn.Dropout()\\n        \\n    def forward(self, content, title):\\n        \\n        content_embed = self.embed(content)\\n        title_embed = self.embed(title)\\n       \\n        t_rep, _ = (self.title_lstm(title_embed))                      #[64, 31, 400]\\n        c_rep, _ = (self.content_lstm(content_embed))                      #[64,637, 400]\\n        title_rep = self.relu(t_rep)\\n        content_rep = self.relu(c_rep)\\n        \\n\\n        t = torch.mean(title_rep, dim = 1)\\n        c = torch.mean(content_rep, dim = 1)\\n        final_rep = torch.cat((t,c), dim = 1)\\n        return F.log_softmax((self.fc1(final_rep)), dim = 1)\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_size, hidden_size,  vocab_size, num_labels ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        self.embed = nn.Embedding(num_embeddings = self.vocab_size, embedding_dim = self.embed_size)\n",
    "        self.embed.weight.requires_grad = False\n",
    "        self.embed.load_state_dict({'weight': weights_matrix})\n",
    "\n",
    "        \n",
    "      \n",
    "        self.title_lstm = nn.LSTM(input_size = self.embed_size, hidden_size = self.hidden_size, bidirectional = True, batch_first = True, num_layers = 2)\n",
    "        self.content_lstm = nn.LSTM(input_size = self.embed_size, hidden_size = self.hidden_size, bidirectional = True, batch_first = True, num_layers = 2)\n",
    "        \n",
    "        self.attention = nn.Linear(2*self.hidden_size, 2*self.hidden_size, bias = False)\n",
    "        \n",
    "        self.fc = nn.Linear(7532, self.num_labels)\n",
    "        self.fc1 = nn.Linear(4*hidden_size, self.num_labels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "        \n",
    "    def forward(self, content, title):\n",
    "        \n",
    "        content_embed = self.embed(content)\n",
    "        title_embed = self.embed(title)\n",
    "       \n",
    "        t_rep, _ = (self.title_lstm(title_embed))                      #[64, 31, 400]\n",
    "        c_rep, _ = (self.content_lstm(content_embed))                      #[64,637, 400]\n",
    "        title_rep = self.relu(t_rep)\n",
    "        content_rep = self.relu(c_rep)\n",
    "        \n",
    "\n",
    "        t = torch.mean(title_rep, dim = 1)\n",
    "        c = torch.mean(content_rep, dim = 1)\n",
    "        final_rep = torch.cat((t,c), dim = 1)\n",
    "        return F.log_softmax((self.fc1(final_rep)), dim = 1)'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KimCNN(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, n_filters, filter_sizes, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
    "        self.embedding.load_state_dict({'weight': weights_matrix})\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "\n",
    "        self.fc = nn.Linear(n_filters*len(filter_sizes), output_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        #x = x.permute(1,0)\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        convs_x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "        pooled_x = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in convs_x]\n",
    "        cat_x = torch.cat(pooled_x, dim = 1)\n",
    "        x = self.fc(cat_x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "841a195f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:07:08.181652Z",
     "iopub.status.busy": "2021-10-31T07:07:08.180809Z",
     "iopub.status.idle": "2021-10-31T07:07:08.191309Z",
     "shell.execute_reply": "2021-10-31T07:07:08.192339Z",
     "shell.execute_reply.started": "2021-10-31T06:56:24.116714Z"
    },
    "papermill": {
     "duration": 0.075603,
     "end_time": "2021-10-31T07:07:08.192522",
     "exception": false,
     "start_time": "2021-10-31T07:07:08.116919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_size, hidden_size,  vocab_size, num_labels ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        self.embed = nn.Embedding(num_embeddings = self.vocab_size, embedding_dim = self.embed_size)\n",
    "        self.embed.weight.requires_grad = False\n",
    "        self.embed.load_state_dict({'weight': weights_matrix})\n",
    "\n",
    "        \n",
    "      \n",
    "    \n",
    "        self.lstm = nn.LSTM(input_size = self.embed_size, hidden_size = self.hidden_size, bidirectional = True, batch_first = True, num_layers = 2)\n",
    "        \n",
    "        self.conv = nn.Conv1d(2*self.hidden_size,64, 3)\n",
    "        self.avg_pool = nn.AvgPool1d(7532)\n",
    "        self.max_pool = nn.MaxPool1d(7532)\n",
    "        self.fc = nn.Linear(128, self.num_labels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, info):\n",
    "        \n",
    "        info_embed = self.embed(info)\n",
    "        i_rep, _ = (self.lstm(info_embed))                      #[32,637, 128]\n",
    "        info_rep = self.relu(i_rep)                             #[32,637,128]\n",
    "        info_conv = self.conv(info_rep.permute(0,2,1))   #[32,64,671]\n",
    "        #info_conv = info_conv.permute(0,2,1)             #[32,671,64]      \n",
    "        info_avg = self.avg_pool(info_conv).squeeze(-1)   #[32,64]\n",
    "        info_max = self.max_pool(info_conv).squeeze(-1)   #[32,64]\n",
    "        info_cat = torch.cat((info_avg, info_max), dim = 1) #[32,128]\n",
    "        \n",
    "\n",
    "        return F.log_softmax(self.fc(info_cat), dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fece5bab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:07:08.315405Z",
     "iopub.status.busy": "2021-10-31T07:07:08.314566Z",
     "iopub.status.idle": "2021-10-31T07:07:16.638690Z",
     "shell.execute_reply": "2021-10-31T07:07:16.638148Z",
     "shell.execute_reply.started": "2021-10-31T06:56:24.136245Z"
    },
    "papermill": {
     "duration": 8.388786,
     "end_time": "2021-10-31T07:07:16.638825",
     "exception": false,
     "start_time": "2021-10-31T07:07:08.250039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "embed_size = 300\n",
    "hidden_size = 64\n",
    "vocab_size = vocab.num_words\n",
    "num_labels = 500\n",
    "model = Model(embed_size, hidden_size, vocab_size, num_labels)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "criterion = criterion.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a470973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:07:16.792865Z",
     "iopub.status.busy": "2021-10-31T07:07:16.791255Z",
     "iopub.status.idle": "2021-10-31T07:07:16.793473Z",
     "shell.execute_reply": "2021-10-31T07:07:16.793869Z",
     "shell.execute_reply.started": "2021-10-31T06:56:32.340249Z"
    },
    "papermill": {
     "duration": 0.044351,
     "end_time": "2021-10-31T07:07:16.793995",
     "exception": false,
     "start_time": "2021-10-31T07:07:16.749644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as acc\n",
    "def train(trainloader, model,  criterion, optimizer, epoch):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    for batch_idx, (c,l) in enumerate(trainloader):\n",
    "        c = c.to(device)\n",
    "        #t = t.to(device)\n",
    "        l = l.to(device)\n",
    "        preds = model(c)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(preds, l)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        p = torch.argmax(preds, dim = 1)\n",
    "        train_acc.append(acc(l.cpu(), p.cpu()))\n",
    "        #if (batch_idx%84 == 0): \n",
    "        #    print(f'epoch {epoch+1}({(int(batch_idx*100/len(trainloader)))}%)  train loss : {(np.mean(train_loss))}   train accuracy : {(np.mean(train_acc)*100)}%')\n",
    "    print(f'\\nepoch {epoch+1}  train loss : {(np.mean(train_loss)):.2f}   train accuracy : {(np.mean(train_acc)*100):.2f}%\\n')\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21ce4dd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:07:16.870267Z",
     "iopub.status.busy": "2021-10-31T07:07:16.869429Z",
     "iopub.status.idle": "2021-10-31T07:07:16.871212Z",
     "shell.execute_reply": "2021-10-31T07:07:16.871656Z",
     "shell.execute_reply.started": "2021-10-31T06:56:32.354172Z"
    },
    "papermill": {
     "duration": 0.043302,
     "end_time": "2021-10-31T07:07:16.871786",
     "exception": false,
     "start_time": "2021-10-31T07:07:16.828484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val(valloader, model,  criterion, epoch):\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    for batch_idx, (c,l) in enumerate(valloader):\n",
    "        c = c.to(device)\n",
    "        #t = t.to(device)\n",
    "        l = l.to(device)\n",
    "        preds = model(c)\n",
    "        loss = criterion(preds, l)\n",
    "        val_loss.append(loss.item())\n",
    "        p = torch.argmax(preds, dim = 1)\n",
    "        val_acc.append(acc(l.cpu(), p.cpu()))\n",
    "#        if (batch_idx%84 == 0): \n",
    "#            print(f'epoch {epoch+1}({(int(batch_idx*100/len(trainloader)))}%)  train loss : {(np.mean(train_loss))}   train accuracy : {(np.mean(train_acc)*100)}%')\n",
    "    print(f'epoch {epoch+1}  val loss : {(np.mean(val_loss)):.2f}   val accuracy : {(np.mean(val_acc)*100):.2f}%\\n')\n",
    "    return np.mean(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1320551c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:07:16.947732Z",
     "iopub.status.busy": "2021-10-31T07:07:16.946172Z",
     "iopub.status.idle": "2021-10-31T07:07:16.948346Z",
     "shell.execute_reply": "2021-10-31T07:07:16.948750Z",
     "shell.execute_reply.started": "2021-10-31T06:56:32.364906Z"
    },
    "papermill": {
     "duration": 0.043025,
     "end_time": "2021-10-31T07:07:16.948876",
     "exception": false,
     "start_time": "2021-10-31T07:07:16.905851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "def test(valloader, model):\n",
    "    preds = []\n",
    "    for batch_idx, (c) in enumerate(valloader):\n",
    "        c = c.to(device)\n",
    "        #t = t.to(device)\n",
    "        predsx = model(c)\n",
    "        p = torch.argmax(predsx, dim = 1)\n",
    "        preds.append([int(pr) for pr in p])\n",
    "    \n",
    "    last = preds[-1]\n",
    "    preds = preds[:-1]\n",
    "    preds = np.array(preds)\n",
    "    p_arr = preds.reshape(-1)\n",
    "    for l in last:\n",
    "        p_arr = np.append(p_arr,l)\n",
    "    print('done')\n",
    "    return p_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd6cbae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T07:07:17.258750Z",
     "iopub.status.busy": "2021-10-31T07:07:17.258033Z",
     "iopub.status.idle": "2021-10-31T14:08:10.955716Z",
     "shell.execute_reply": "2021-10-31T14:08:10.956497Z",
     "shell.execute_reply.started": "2021-10-31T06:56:32.411939Z"
    },
    "papermill": {
     "duration": 25253.739355,
     "end_time": "2021-10-31T14:08:10.956766",
     "exception": false,
     "start_time": "2021-10-31T07:07:17.217411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1  train loss : 3.86   train accuracy : 19.65%\n",
      "\n",
      "epoch 1  val loss : 3.05   val accuracy : 26.96%\n",
      "\n",
      "\n",
      "epoch 2  train loss : 2.68   train accuracy : 30.19%\n",
      "\n",
      "epoch 2  val loss : 2.50   val accuracy : 32.39%\n",
      "\n",
      "\n",
      "epoch 3  train loss : 2.21   train accuracy : 35.71%\n",
      "\n",
      "epoch 3  val loss : 2.21   val accuracy : 35.49%\n",
      "\n",
      "\n",
      "epoch 4  train loss : 1.99   train accuracy : 38.11%\n",
      "\n",
      "epoch 4  val loss : 2.09   val accuracy : 37.54%\n",
      "\n",
      "\n",
      "epoch 5  train loss : 1.84   train accuracy : 40.10%\n",
      "\n",
      "epoch 5  val loss : 2.03   val accuracy : 38.08%\n",
      "\n",
      "\n",
      "epoch 6  train loss : 1.74   train accuracy : 42.30%\n",
      "\n",
      "epoch 6  val loss : 1.98   val accuracy : 38.90%\n",
      "\n",
      "\n",
      "epoch 7  train loss : 1.66   train accuracy : 43.52%\n",
      "\n",
      "epoch 7  val loss : 2.01   val accuracy : 38.66%\n",
      "\n",
      "\n",
      "epoch 8  train loss : 1.61   train accuracy : 44.42%\n",
      "\n",
      "epoch 8  val loss : 2.00   val accuracy : 39.80%\n",
      "\n",
      "\n",
      "epoch 9  train loss : 1.56   train accuracy : 45.16%\n",
      "\n",
      "epoch 9  val loss : 1.96   val accuracy : 39.48%\n",
      "\n",
      "\n",
      "epoch 10  train loss : 1.52   train accuracy : 46.03%\n",
      "\n",
      "epoch 10  val loss : 2.00   val accuracy : 39.68%\n",
      "\n",
      "\n",
      "epoch 11  train loss : 1.49   train accuracy : 47.02%\n",
      "\n",
      "epoch 11  val loss : 2.01   val accuracy : 39.88%\n",
      "\n",
      "\n",
      "epoch 12  train loss : 1.45   train accuracy : 47.46%\n",
      "\n",
      "epoch 12  val loss : 2.01   val accuracy : 39.75%\n",
      "\n",
      "\n",
      "epoch 13  train loss : 1.44   train accuracy : 47.87%\n",
      "\n",
      "epoch 13  val loss : 2.05   val accuracy : 39.93%\n",
      "\n",
      "\n",
      "epoch 14  train loss : 1.41   train accuracy : 48.11%\n",
      "\n",
      "epoch 14  val loss : 2.03   val accuracy : 39.37%\n",
      "\n",
      "\n",
      "epoch 15  train loss : 1.40   train accuracy : 48.51%\n",
      "\n",
      "epoch 15  val loss : 2.03   val accuracy : 39.12%\n",
      "\n",
      "\n",
      "epoch 16  train loss : 1.38   train accuracy : 49.09%\n",
      "\n",
      "epoch 16  val loss : 2.08   val accuracy : 39.43%\n",
      "\n",
      "\n",
      "epoch 17  train loss : 1.35   train accuracy : 49.70%\n",
      "\n",
      "epoch 17  val loss : 2.13   val accuracy : 39.91%\n",
      "\n",
      "\n",
      "epoch 18  train loss : 1.35   train accuracy : 49.55%\n",
      "\n",
      "epoch 18  val loss : 2.06   val accuracy : 40.00%\n",
      "\n",
      "\n",
      "epoch 19  train loss : 1.32   train accuracy : 50.54%\n",
      "\n",
      "epoch 19  val loss : 2.11   val accuracy : 40.25%\n",
      "\n",
      "\n",
      "epoch 20  train loss : 1.30   train accuracy : 50.69%\n",
      "\n",
      "epoch 20  val loss : 2.11   val accuracy : 39.79%\n",
      "\n",
      "\n",
      "epoch 21  train loss : 1.29   train accuracy : 50.68%\n",
      "\n",
      "epoch 21  val loss : 2.06   val accuracy : 39.89%\n",
      "\n",
      "\n",
      "epoch 22  train loss : 1.25   train accuracy : 51.83%\n",
      "\n",
      "epoch 22  val loss : 2.11   val accuracy : 39.43%\n",
      "\n",
      "\n",
      "epoch 23  train loss : 1.24   train accuracy : 52.06%\n",
      "\n",
      "epoch 23  val loss : 2.16   val accuracy : 39.75%\n",
      "\n",
      "\n",
      "epoch 24  train loss : 1.25   train accuracy : 51.59%\n",
      "\n",
      "epoch 24  val loss : 2.08   val accuracy : 39.91%\n",
      "\n",
      "\n",
      "epoch 25  train loss : 1.24   train accuracy : 52.02%\n",
      "\n",
      "epoch 25  val loss : 2.12   val accuracy : 39.73%\n",
      "\n",
      "\n",
      "epoch 26  train loss : 1.22   train accuracy : 52.58%\n",
      "\n",
      "epoch 26  val loss : 2.13   val accuracy : 40.07%\n",
      "\n",
      "\n",
      "epoch 27  train loss : 1.22   train accuracy : 52.41%\n",
      "\n",
      "epoch 27  val loss : 2.15   val accuracy : 39.87%\n",
      "\n",
      "\n",
      "epoch 28  train loss : 1.20   train accuracy : 53.03%\n",
      "\n",
      "epoch 28  val loss : 2.17   val accuracy : 40.30%\n",
      "\n",
      "\n",
      "epoch 29  train loss : 1.21   train accuracy : 52.78%\n",
      "\n",
      "epoch 29  val loss : 2.22   val accuracy : 39.91%\n",
      "\n",
      "\n",
      "epoch 30  train loss : 1.19   train accuracy : 53.17%\n",
      "\n",
      "epoch 30  val loss : 2.19   val accuracy : 39.56%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load('./weights.pth'))\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr = 1e-1)\n",
    "epochs = 30\n",
    "best_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    x = train(trainloader, model, criterion, optimizer, epoch)\n",
    "    y = val(valloader, model, criterion, epoch)\n",
    "    if y >= best_acc:\n",
    "        torch.save(model.state_dict(), 'weights.pth')\n",
    "        best_acc = y\n",
    "    if epoch == 10:\n",
    "        torch.save(model.state_dict(), 'weights_10.pth')\n",
    "        \n",
    "    if epoch == 20:\n",
    "        torch.save(model.state_dict(), 'weights_20.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bae921ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T14:08:11.140850Z",
     "iopub.status.busy": "2021-10-31T14:08:11.140093Z",
     "iopub.status.idle": "2021-10-31T14:14:29.385187Z",
     "shell.execute_reply": "2021-10-31T14:14:29.385845Z",
     "shell.execute_reply.started": "2021-10-31T06:57:59.239416Z"
    },
    "papermill": {
     "duration": 378.3424,
     "end_time": "2021-10-31T14:14:29.386058",
     "exception": false,
     "start_time": "2021-10-31T14:08:11.043658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "preds = test(testloader, model)\n",
    "submission = pd.DataFrame({'uid': [t for t in test_df['uid']], 'target_ind': preds})\n",
    "submission.to_csv('submission.csv')\n",
    "\n",
    "model.load_state_dict(torch.load('./weights.pth'))\n",
    "preds = test(testloader, model)\n",
    "submission_weights = pd.DataFrame({'uid': [t for t in test_df['uid']], 'target_ind': preds})\n",
    "submission_weights.to_csv('submission_weights.csv')\n",
    "\n",
    "model.load_state_dict(torch.load('./weights_10.pth'))\n",
    "preds = test(testloader, model)\n",
    "submission_weights = pd.DataFrame({'uid': [t for t in test_df['uid']], 'target_ind': preds})\n",
    "submission_weights.to_csv('submission_weights_10.csv')\n",
    "\n",
    "model.load_state_dict(torch.load('./weights_20.pth'))\n",
    "preds = test(testloader, model)\n",
    "submission_weights = pd.DataFrame({'uid': [t for t in test_df['uid']], 'target_ind': preds})\n",
    "submission_weights.to_csv('submission_weights_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ebc2ee",
   "metadata": {
    "papermill": {
     "duration": 0.05299,
     "end_time": "2021-10-31T14:14:29.494642",
     "exception": false,
     "start_time": "2021-10-31T14:14:29.441652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25921.757499,
   "end_time": "2021-10-31T14:14:33.306817",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-31T07:02:31.549318",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
